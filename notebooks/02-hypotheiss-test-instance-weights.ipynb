{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39f8142f-a5c3-4301-87d6-379e09492cf5",
   "metadata": {},
   "source": [
    "# Distribution Matching for Edge Weights in NetworkX Graphs\n",
    "\n",
    "## Overview\n",
    "In this notebook, we aim to identify which probability distribution most closely matches the edge weights of a given NetworkX graph. The distributions considered include:\n",
    "- Uniform (-1, 1)\n",
    "- Uniform (0, 1)\n",
    "- Normal (0, 1)\n",
    "- Lognormal (0, 1)\n",
    "- Exponential $(\\lambda = 0.2)$\n",
    "- Standard Cauchy\n",
    "\n",
    "## Approach\n",
    "To determine the best matching distribution for the edge weights, we follow these steps:\n",
    "\n",
    "### 1. Generate Reference Samples\n",
    "We generate a large number of samples from each of the candidate distributions to serve as references for comparison.\n",
    "\n",
    "### 2. Extract Edge Weights from the Graph\n",
    "We read the NetworkX graph and extract the edge weights, which will be compared against the reference samples.\n",
    "\n",
    "### 3. Define Goodness-of-Fit Function\n",
    "We define a goodness-of-fit function using the Kolmogorov-Smirnov (K-S) test to measure how well the edge weights match each candidate distribution.\n",
    "\n",
    "### 4. Parallel Processing for Scalability\n",
    "To efficiently handle thousands of instances, we use parallel processing to compute the goodness-of-fit statistics for each set of edge weights.\n",
    "\n",
    "### 5. Determine Best Matching Distribution\n",
    "Finally, we determine the best matching distribution by identifying which candidate distribution has the lowest K-S statistic.\n",
    "\n",
    "## Implementation\n",
    "The implementation is divided into several sections:\n",
    "1. **Import Libraries**: Import necessary libraries for data handling, statistical analysis, and parallel processing.\n",
    "2. **Generate Reference Samples**: Generate and store reference samples for each candidate distribution.\n",
    "3. **Extract Edge Weights**: Read the NetworkX graph and extract the edge weights.\n",
    "4. **Goodness-of-Fit Function**: Define the K-S test function to compare distributions.\n",
    "5. **Parallel Comparison**: Use parallel processing to compare the edge weights with each reference distribution.\n",
    "6. **Determine Best Match**: Identify the best matching distribution based on the goodness-of-fit statistics.\n",
    "\n",
    "By following this structured approach, we can efficiently and accurately determine the distribution that most closely matches the edge weights of the given graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8abbde33-2bd3-4369-a146-3c05ccc412ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "\n",
    "experiment = \"INFORMS-Revision-12-node-network\"\n",
    "# Load your graph (example using a random graph)\n",
    "G = nx.erdos_renyi_graph(100, 0.1)  # Replace with your actual graph\n",
    "\n",
    "# Add random weights to edges (for demonstration)\n",
    "for (u, v, w) in G.edges(data=True):\n",
    "    w['weight'] = np.random.uniform(-1, 1)  # Replace with actual weights if available\n",
    "\n",
    "# Extract edge weights\n",
    "edge_weights = np.array([w['weight'] for (u, v, w) in G.edges(data=True)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "214965a3-5161-492c-bbd7-68fcf14048a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100000\n",
    "\n",
    "uniform_samples = [random.uniform(0, 1) for _ in range(n_samples)]\n",
    "uniform_plus_samples = [random.uniform(-1, 1) for _ in range(n_samples)]\n",
    "normal_samples = [random.normalvariate(0, 1) for _ in range(n_samples)]\n",
    "exponential_samples = [random.expovariate(0.2) for _ in range(n_samples)]\n",
    "lognormal_samples = [random.lognormvariate(0, 1) for _ in range(n_samples)]\n",
    "cauchy_samples = [np.random.standard_cauchy() for _ in range(n_samples)]\n",
    "\n",
    "distributions = {\n",
    "    'uniform': uniform_plus_samples,\n",
    "    'uniform_plus': uniform_samples,\n",
    "    'normal': normal_samples,\n",
    "    'log-normal': lognormal_samples,\n",
    "    'exponential': exponential_samples,\n",
    "    'cauchy': cauchy_samples\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e7aac96-d0b7-416c-99ff-01e6730ab344",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def goodness_of_fit(test_data, ref_data):\n",
    "    return ks_2samp(test_data, ref_data).statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86beb97a-c838-4f48-a34c-924a204f4ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def test_goodness_of_fit_all():\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    random.seed(42)  # For reproducibility with random.expovariate\n",
    "\n",
    "    # Generate sample data for each distribution\n",
    "    test_data_uniform_minus1_1 = np.random.uniform(-1, 1, 1000)\n",
    "    ref_data_uniform_minus1_1 = np.random.uniform(-1, 1, 1000)\n",
    "    \n",
    "    test_data_uniform_0_1 = np.random.uniform(0, 1, 1000)\n",
    "    ref_data_uniform_0_1 = np.random.uniform(0, 1, 1000)\n",
    "    \n",
    "    test_data_normal_0_1 = np.random.normal(0, 1, 1000)\n",
    "    ref_data_normal_0_1 = np.random.normal(0, 1, 1000)\n",
    "    \n",
    "    test_data_lognormal_0_1 = np.random.lognormal(0, 1, 1000)\n",
    "    ref_data_lognormal_0_1 = np.random.lognormal(0, 1, 1000)\n",
    "    \n",
    "    test_data_exponential_0_2 = [random.expovariate(0.2) for _ in range(1000)]\n",
    "    ref_data_exponential_0_2 = [random.expovariate(0.2) for _ in range(1000)]\n",
    "    \n",
    "    test_data_cauchy = np.random.standard_cauchy(1000)\n",
    "    ref_data_cauchy = np.random.standard_cauchy(1000)\n",
    "    \n",
    "    # Test data drawn from one distribution and reference data from another\n",
    "    test_data_mixed = np.random.uniform(0, 1, 1000)\n",
    "    ref_data_mixed = np.random.normal(0, 1, 1000)\n",
    "\n",
    "    # Compute K-S statistics using the goodness-of-fit function\n",
    "    ks_stat_uniform_minus1_1 = goodness_of_fit(test_data_uniform_minus1_1, ref_data_uniform_minus1_1)\n",
    "    ks_stat_uniform_0_1 = goodness_of_fit(test_data_uniform_0_1, ref_data_uniform_0_1)\n",
    "    ks_stat_normal_0_1 = goodness_of_fit(test_data_normal_0_1, ref_data_normal_0_1)\n",
    "    ks_stat_lognormal_0_1 = goodness_of_fit(test_data_lognormal_0_1, ref_data_lognormal_0_1)\n",
    "    ks_stat_exponential_0_2 = goodness_of_fit(test_data_exponential_0_2, ref_data_exponential_0_2)\n",
    "    ks_stat_cauchy = goodness_of_fit(test_data_cauchy, ref_data_cauchy)\n",
    "    ks_stat_mixed = goodness_of_fit(test_data_mixed, ref_data_mixed)\n",
    "\n",
    "    # Expected K-S statistics using scipy's ks_2samp directly\n",
    "    expected_ks_stat_uniform_minus1_1 = ks_2samp(test_data_uniform_minus1_1, ref_data_uniform_minus1_1).statistic\n",
    "    expected_ks_stat_uniform_0_1 = ks_2samp(test_data_uniform_0_1, ref_data_uniform_0_1).statistic\n",
    "    expected_ks_stat_normal_0_1 = ks_2samp(test_data_normal_0_1, ref_data_normal_0_1).statistic\n",
    "    expected_ks_stat_lognormal_0_1 = ks_2samp(test_data_lognormal_0_1, ref_data_lognormal_0_1).statistic\n",
    "    expected_ks_stat_exponential_0_2 = ks_2samp(test_data_exponential_0_2, ref_data_exponential_0_2).statistic\n",
    "    expected_ks_stat_cauchy = ks_2samp(test_data_cauchy, ref_data_cauchy).statistic\n",
    "    expected_ks_stat_mixed = ks_2samp(test_data_mixed, ref_data_mixed).statistic\n",
    "\n",
    "    # Assertions to check if the computed K-S statistics match the expected values\n",
    "    assert np.isclose(ks_stat_uniform_minus1_1, expected_ks_stat_uniform_minus1_1), f\"Uniform (-1, 1) test failed: {ks_stat_uniform_minus1_1} != {expected_ks_stat_uniform_minus1_1}\"\n",
    "    assert np.isclose(ks_stat_uniform_0_1, expected_ks_stat_uniform_0_1), f\"Uniform (0, 1) test failed: {ks_stat_uniform_0_1} != {expected_ks_stat_uniform_0_1}\"\n",
    "    assert np.isclose(ks_stat_normal_0_1, expected_ks_stat_normal_0_1), f\"Normal (0, 1) test failed: {ks_stat_normal_0_1} != {expected_ks_stat_normal_0_1}\"\n",
    "    assert np.isclose(ks_stat_lognormal_0_1, expected_ks_stat_lognormal_0_1), f\"Lognormal (0, 1) test failed: {ks_stat_lognormal_0_1} != {expected_ks_stat_lognormal_0_1}\"\n",
    "    assert np.isclose(ks_stat_exponential_0_2, expected_ks_stat_exponential_0_2), f\"Exponential (Î»=0.2) test failed: {ks_stat_exponential_0_2} != {expected_ks_stat_exponential_0_2}\"\n",
    "    assert np.isclose(ks_stat_cauchy, expected_ks_stat_cauchy), f\"Cauchy test failed: {ks_stat_cauchy} != {expected_ks_stat_cauchy}\"\n",
    "    assert np.isclose(ks_stat_mixed, expected_ks_stat_mixed), f\"Mixed distribution test failed: {ks_stat_mixed} != {expected_ks_stat_mixed}\"\n",
    "\n",
    "    print(\"All tests passed!\")\n",
    "\n",
    "# Run the test\n",
    "test_goodness_of_fit_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719fef92-6337-4bb7-bf06-2cb7258ded88",
   "metadata": {},
   "source": [
    "# Read in instances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6db45b8-2ce1-45a6-b23b-209b62c0bfbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total graphs read: 284\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the directory containing the graph files\n",
    "directory_path = f'../{experiment}/best_graphs_12/'\n",
    "\n",
    "# Initialize an empty list to store the graphs\n",
    "graphs = []\n",
    "filenames = os.listdir(directory_path)\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for filename in filenames:\n",
    "    if filename.endswith('.graphml'):  # Modify this condition for other formats\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        try:\n",
    "            G = nx.read_graphml(file_path)  # Use appropriate read function for other formats\n",
    "            graphs.append(G)\n",
    "        except Exception as e:\n",
    "            print(f'Failed to read {filename}: {e}')\n",
    "\n",
    "# Print the number of graphs read\n",
    "print(f'Total graphs read: {len(graphs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18e1114f-bd31-4bc6-a15f-532c1a1a2ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_edge_weights(graph):\n",
    "    return [data.get('weight', 0) for _, _, data in graph.edges(data=True)]\n",
    "\n",
    "edge_weights_list = [extract_edge_weights(graph) for graph in graphs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea15fdc5-a38a-4b62-917d-c20745671a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parallel Processing for Goodness-of-Fit comparison\n",
    "def compare_distribution(test_data, distributions):\n",
    "    results = {}\n",
    "    for dist_name, ref_data in distributions.items():\n",
    "        results[dist_name] = goodness_of_fit(test_data, ref_data)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee8258ec-223e-49dd-8828-980eda668896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Comparing distributions: 100%|âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 284/284 [00:29<00:00,  9.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run the comparison with progress tracking\n",
    "results = []\n",
    "for edge_weights in tqdm(edge_weights_list, desc=\"Comparing distributions\"):\n",
    "    result = compare_distribution(edge_weights, distributions)\n",
    "    results.append(result)\n",
    "\n",
    "# Determine Best Match\n",
    "def determine_best_match(results):\n",
    "    best_matches = []\n",
    "    for result in results:\n",
    "        best_match = min(result, key=result.get)\n",
    "        best_matches.append(best_match)\n",
    "    return best_matches\n",
    "\n",
    "best_matches = determine_best_match(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6eb42f6c-0148-47ab-88d0-51ebe4342337",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d_instances = pd.read_csv(f\"../{experiment}/final_evolved_instances_n_12_with_source.csv\")\n",
    "\n",
    "filenames = [file for file in filenames if '.graphml' in file]\n",
    "# Create DataFrame to hold filenames and their corresponding best matches\n",
    "new_weight_df = pd.DataFrame({'instance': filenames, 'weight_type': best_matches})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fcd361e6-4497-4a74-9314-bff0967ade65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z_1</th>\n",
       "      <th>z_2</th>\n",
       "      <th>Source</th>\n",
       "      <th>Source_new</th>\n",
       "      <th>instance_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.390078</td>\n",
       "      <td>1.447221</td>\n",
       "      <td>target_point_1.3447058823529414_1.285294117647...</td>\n",
       "      <td>nearly_complete_bipartite_target_point_1.34470...</td>\n",
       "      <td>nearly_complete_bipartite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.033745</td>\n",
       "      <td>1.863531</td>\n",
       "      <td>target_point_0.631578947368421_2.6789473684210...</td>\n",
       "      <td>nearly_complete_bipartite_target_point_0.63157...</td>\n",
       "      <td>nearly_complete_bipartite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.460238</td>\n",
       "      <td>0.859186</td>\n",
       "      <td>target_point_-1.6666666666666667_0.83333333333...</td>\n",
       "      <td>power_law_tree_target_point_-1.666666666666666...</td>\n",
       "      <td>power_law_tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.153573</td>\n",
       "      <td>2.779136</td>\n",
       "      <td>target_point_0.8421052631578947_2.605263157894...</td>\n",
       "      <td>nearly_complete_bipartite_target_point_0.84210...</td>\n",
       "      <td>nearly_complete_bipartite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.089295</td>\n",
       "      <td>2.514753</td>\n",
       "      <td>target_point_1.102941176470588_2.0658823529411...</td>\n",
       "      <td>nearly_complete_bipartite_target_point_1.10294...</td>\n",
       "      <td>nearly_complete_bipartite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>-0.032185</td>\n",
       "      <td>1.630777</td>\n",
       "      <td>target_point_0.3441176470588235_2.145058823529...</td>\n",
       "      <td>nearly_complete_bipartite_target_point_0.34411...</td>\n",
       "      <td>nearly_complete_bipartite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>-2.144231</td>\n",
       "      <td>-0.961832</td>\n",
       "      <td>target_point_-1.7999999999999998_-0.9071428571...</td>\n",
       "      <td>3_regular_graph_target_point_-1.79999999999999...</td>\n",
       "      <td>3_regular_graph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>1.634686</td>\n",
       "      <td>0.857115</td>\n",
       "      <td>target_point_1.8205882352941174_0.794117647058...</td>\n",
       "      <td>uniform_random_target_point_1.8205882352941174...</td>\n",
       "      <td>uniform_random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>-1.780164</td>\n",
       "      <td>0.523360</td>\n",
       "      <td>target_point_-2.0588235294117645_0.94117647058...</td>\n",
       "      <td>power_law_tree_target_point_-2.058823529411764...</td>\n",
       "      <td>power_law_tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>-3.004135</td>\n",
       "      <td>-0.815686</td>\n",
       "      <td>target_point_-2.85_-1.1_n_12_best_graph_gen_34...</td>\n",
       "      <td>power_law_tree_target_point_-2.85_-1.1_n_12_be...</td>\n",
       "      <td>power_law_tree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284 rows Ã 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          z_1       z_2                                             Source  \\\n",
       "0    1.390078  1.447221  target_point_1.3447058823529414_1.285294117647...   \n",
       "1    1.033745  1.863531  target_point_0.631578947368421_2.6789473684210...   \n",
       "2   -1.460238  0.859186  target_point_-1.6666666666666667_0.83333333333...   \n",
       "3   -0.153573  2.779136  target_point_0.8421052631578947_2.605263157894...   \n",
       "4    0.089295  2.514753  target_point_1.102941176470588_2.0658823529411...   \n",
       "..        ...       ...                                                ...   \n",
       "279 -0.032185  1.630777  target_point_0.3441176470588235_2.145058823529...   \n",
       "280 -2.144231 -0.961832  target_point_-1.7999999999999998_-0.9071428571...   \n",
       "281  1.634686  0.857115  target_point_1.8205882352941174_0.794117647058...   \n",
       "282 -1.780164  0.523360  target_point_-2.0588235294117645_0.94117647058...   \n",
       "283 -3.004135 -0.815686  target_point_-2.85_-1.1_n_12_best_graph_gen_34...   \n",
       "\n",
       "                                            Source_new  \\\n",
       "0    nearly_complete_bipartite_target_point_1.34470...   \n",
       "1    nearly_complete_bipartite_target_point_0.63157...   \n",
       "2    power_law_tree_target_point_-1.666666666666666...   \n",
       "3    nearly_complete_bipartite_target_point_0.84210...   \n",
       "4    nearly_complete_bipartite_target_point_1.10294...   \n",
       "..                                                 ...   \n",
       "279  nearly_complete_bipartite_target_point_0.34411...   \n",
       "280  3_regular_graph_target_point_-1.79999999999999...   \n",
       "281  uniform_random_target_point_1.8205882352941174...   \n",
       "282  power_law_tree_target_point_-2.058823529411764...   \n",
       "283  power_law_tree_target_point_-2.85_-1.1_n_12_be...   \n",
       "\n",
       "                instance_class  \n",
       "0    nearly_complete_bipartite  \n",
       "1    nearly_complete_bipartite  \n",
       "2               power_law_tree  \n",
       "3    nearly_complete_bipartite  \n",
       "4    nearly_complete_bipartite  \n",
       "..                         ...  \n",
       "279  nearly_complete_bipartite  \n",
       "280            3_regular_graph  \n",
       "281             uniform_random  \n",
       "282             power_law_tree  \n",
       "283             power_law_tree  \n",
       "\n",
       "[284 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ec5268f-2064-4933-87ee-2c360957eec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance</th>\n",
       "      <th>weight_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>target_point_1.3447058823529414_1.285294117647...</td>\n",
       "      <td>uniform_plus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>target_point_0.631578947368421_2.6789473684210...</td>\n",
       "      <td>log-normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>target_point_-1.6666666666666667_0.83333333333...</td>\n",
       "      <td>cauchy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>target_point_0.8421052631578947_2.605263157894...</td>\n",
       "      <td>log-normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>target_point_1.102941176470588_2.0658823529411...</td>\n",
       "      <td>log-normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>target_point_0.3441176470588235_2.145058823529...</td>\n",
       "      <td>uniform_plus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>target_point_-1.7999999999999998_-0.9071428571...</td>\n",
       "      <td>uniform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>target_point_1.8205882352941174_0.794117647058...</td>\n",
       "      <td>log-normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>target_point_-2.0588235294117645_0.94117647058...</td>\n",
       "      <td>cauchy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>target_point_-2.85_-1.1_n_12_best_graph_gen_34...</td>\n",
       "      <td>uniform</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284 rows Ã 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              instance   weight_type\n",
       "0    target_point_1.3447058823529414_1.285294117647...  uniform_plus\n",
       "1    target_point_0.631578947368421_2.6789473684210...    log-normal\n",
       "2    target_point_-1.6666666666666667_0.83333333333...        cauchy\n",
       "3    target_point_0.8421052631578947_2.605263157894...    log-normal\n",
       "4    target_point_1.102941176470588_2.0658823529411...    log-normal\n",
       "..                                                 ...           ...\n",
       "279  target_point_0.3441176470588235_2.145058823529...  uniform_plus\n",
       "280  target_point_-1.7999999999999998_-0.9071428571...       uniform\n",
       "281  target_point_1.8205882352941174_0.794117647058...    log-normal\n",
       "282  target_point_-2.0588235294117645_0.94117647058...        cauchy\n",
       "283  target_point_-2.85_-1.1_n_12_best_graph_gen_34...       uniform\n",
       "\n",
       "[284 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_weight_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d17b3df9-2a26-48f3-b84b-91dcfb260f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = d_instances.merge(new_weight_df, left_on='Source', right_on='instance', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "141ba5ed-1b9f-4a75-98a4-5acb19d50f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z_1</th>\n",
       "      <th>z_2</th>\n",
       "      <th>Source</th>\n",
       "      <th>Source_new</th>\n",
       "      <th>instance_class</th>\n",
       "      <th>instance</th>\n",
       "      <th>weight_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.390078</td>\n",
       "      <td>1.447221</td>\n",
       "      <td>target_point_1.3447058823529414_1.285294117647...</td>\n",
       "      <td>nearly_complete_bipartite_target_point_1.34470...</td>\n",
       "      <td>nearly_complete_bipartite</td>\n",
       "      <td>target_point_1.3447058823529414_1.285294117647...</td>\n",
       "      <td>uniform_plus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.033745</td>\n",
       "      <td>1.863531</td>\n",
       "      <td>target_point_0.631578947368421_2.6789473684210...</td>\n",
       "      <td>nearly_complete_bipartite_target_point_0.63157...</td>\n",
       "      <td>nearly_complete_bipartite</td>\n",
       "      <td>target_point_0.631578947368421_2.6789473684210...</td>\n",
       "      <td>log-normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.460238</td>\n",
       "      <td>0.859186</td>\n",
       "      <td>target_point_-1.6666666666666667_0.83333333333...</td>\n",
       "      <td>power_law_tree_target_point_-1.666666666666666...</td>\n",
       "      <td>power_law_tree</td>\n",
       "      <td>target_point_-1.6666666666666667_0.83333333333...</td>\n",
       "      <td>cauchy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.153573</td>\n",
       "      <td>2.779136</td>\n",
       "      <td>target_point_0.8421052631578947_2.605263157894...</td>\n",
       "      <td>nearly_complete_bipartite_target_point_0.84210...</td>\n",
       "      <td>nearly_complete_bipartite</td>\n",
       "      <td>target_point_0.8421052631578947_2.605263157894...</td>\n",
       "      <td>log-normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.089295</td>\n",
       "      <td>2.514753</td>\n",
       "      <td>target_point_1.102941176470588_2.0658823529411...</td>\n",
       "      <td>nearly_complete_bipartite_target_point_1.10294...</td>\n",
       "      <td>nearly_complete_bipartite</td>\n",
       "      <td>target_point_1.102941176470588_2.0658823529411...</td>\n",
       "      <td>log-normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>-0.032185</td>\n",
       "      <td>1.630777</td>\n",
       "      <td>target_point_0.3441176470588235_2.145058823529...</td>\n",
       "      <td>nearly_complete_bipartite_target_point_0.34411...</td>\n",
       "      <td>nearly_complete_bipartite</td>\n",
       "      <td>target_point_0.3441176470588235_2.145058823529...</td>\n",
       "      <td>uniform_plus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>-2.144231</td>\n",
       "      <td>-0.961832</td>\n",
       "      <td>target_point_-1.7999999999999998_-0.9071428571...</td>\n",
       "      <td>3_regular_graph_target_point_-1.79999999999999...</td>\n",
       "      <td>3_regular_graph</td>\n",
       "      <td>target_point_-1.7999999999999998_-0.9071428571...</td>\n",
       "      <td>uniform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>1.634686</td>\n",
       "      <td>0.857115</td>\n",
       "      <td>target_point_1.8205882352941174_0.794117647058...</td>\n",
       "      <td>uniform_random_target_point_1.8205882352941174...</td>\n",
       "      <td>uniform_random</td>\n",
       "      <td>target_point_1.8205882352941174_0.794117647058...</td>\n",
       "      <td>log-normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>-1.780164</td>\n",
       "      <td>0.523360</td>\n",
       "      <td>target_point_-2.0588235294117645_0.94117647058...</td>\n",
       "      <td>power_law_tree_target_point_-2.058823529411764...</td>\n",
       "      <td>power_law_tree</td>\n",
       "      <td>target_point_-2.0588235294117645_0.94117647058...</td>\n",
       "      <td>cauchy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>-3.004135</td>\n",
       "      <td>-0.815686</td>\n",
       "      <td>target_point_-2.85_-1.1_n_12_best_graph_gen_34...</td>\n",
       "      <td>power_law_tree_target_point_-2.85_-1.1_n_12_be...</td>\n",
       "      <td>power_law_tree</td>\n",
       "      <td>target_point_-2.85_-1.1_n_12_best_graph_gen_34...</td>\n",
       "      <td>uniform</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284 rows Ã 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          z_1       z_2                                             Source  \\\n",
       "0    1.390078  1.447221  target_point_1.3447058823529414_1.285294117647...   \n",
       "1    1.033745  1.863531  target_point_0.631578947368421_2.6789473684210...   \n",
       "2   -1.460238  0.859186  target_point_-1.6666666666666667_0.83333333333...   \n",
       "3   -0.153573  2.779136  target_point_0.8421052631578947_2.605263157894...   \n",
       "4    0.089295  2.514753  target_point_1.102941176470588_2.0658823529411...   \n",
       "..        ...       ...                                                ...   \n",
       "279 -0.032185  1.630777  target_point_0.3441176470588235_2.145058823529...   \n",
       "280 -2.144231 -0.961832  target_point_-1.7999999999999998_-0.9071428571...   \n",
       "281  1.634686  0.857115  target_point_1.8205882352941174_0.794117647058...   \n",
       "282 -1.780164  0.523360  target_point_-2.0588235294117645_0.94117647058...   \n",
       "283 -3.004135 -0.815686  target_point_-2.85_-1.1_n_12_best_graph_gen_34...   \n",
       "\n",
       "                                            Source_new  \\\n",
       "0    nearly_complete_bipartite_target_point_1.34470...   \n",
       "1    nearly_complete_bipartite_target_point_0.63157...   \n",
       "2    power_law_tree_target_point_-1.666666666666666...   \n",
       "3    nearly_complete_bipartite_target_point_0.84210...   \n",
       "4    nearly_complete_bipartite_target_point_1.10294...   \n",
       "..                                                 ...   \n",
       "279  nearly_complete_bipartite_target_point_0.34411...   \n",
       "280  3_regular_graph_target_point_-1.79999999999999...   \n",
       "281  uniform_random_target_point_1.8205882352941174...   \n",
       "282  power_law_tree_target_point_-2.058823529411764...   \n",
       "283  power_law_tree_target_point_-2.85_-1.1_n_12_be...   \n",
       "\n",
       "                instance_class  \\\n",
       "0    nearly_complete_bipartite   \n",
       "1    nearly_complete_bipartite   \n",
       "2               power_law_tree   \n",
       "3    nearly_complete_bipartite   \n",
       "4    nearly_complete_bipartite   \n",
       "..                         ...   \n",
       "279  nearly_complete_bipartite   \n",
       "280            3_regular_graph   \n",
       "281             uniform_random   \n",
       "282             power_law_tree   \n",
       "283             power_law_tree   \n",
       "\n",
       "                                              instance   weight_type  \n",
       "0    target_point_1.3447058823529414_1.285294117647...  uniform_plus  \n",
       "1    target_point_0.631578947368421_2.6789473684210...    log-normal  \n",
       "2    target_point_-1.6666666666666667_0.83333333333...        cauchy  \n",
       "3    target_point_0.8421052631578947_2.605263157894...    log-normal  \n",
       "4    target_point_1.102941176470588_2.0658823529411...    log-normal  \n",
       "..                                                 ...           ...  \n",
       "279  target_point_0.3441176470588235_2.145058823529...  uniform_plus  \n",
       "280  target_point_-1.7999999999999998_-0.9071428571...       uniform  \n",
       "281  target_point_1.8205882352941174_0.794117647058...    log-normal  \n",
       "282  target_point_-2.0588235294117645_0.94117647058...        cauchy  \n",
       "283  target_point_-2.85_-1.1_n_12_best_graph_gen_34...       uniform  \n",
       "\n",
       "[284 rows x 7 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6fe6f52d-a2ea-44b4-b38e-83f1341b1cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in each graph and add an attribute for the instance_class and weight_type\n",
    "# Process each graph listed in the `instance` column of `merged_df`\n",
    "for index, row in merged_df.iterrows():\n",
    "    graph_file = row['instance']\n",
    "    \n",
    "    try:\n",
    "        # Read the graph\n",
    "        graph = nx.read_graphml(f\"{directory_path}/{graph_file}\")\n",
    "        \n",
    "        # Retrieve instance_class and weight_type\n",
    "        instance_class = row['instance_class']\n",
    "        weight_type = row['weight_type']\n",
    "        \n",
    "        # Add attributes to the graph\n",
    "        graph.graph['instance_class'] = instance_class\n",
    "        graph.graph['weight_type'] = weight_type\n",
    "        \n",
    "        # Save the graph with the new attributes\n",
    "        nx.write_graphml(graph, f'../{experiment}/spartan-ready-instances/{graph_file}')  # Adjust the path as necessary\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {graph_file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d10b9b87-bad8-4211-8644-aa3543c94179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph: ../INFORMS-Revision-12-node-network/spartan-ready-instances/target_point_2.25_0.01_n_12_best_graph_gen_1276.graphml\n",
      "Instance Class: geometric\n",
      "Weight Type: cauchy\n"
     ]
    }
   ],
   "source": [
    "# Test that it worked\n",
    "graph_file_to_check = f'../{experiment}/spartan-ready-instances/target_point_2.25_0.01_n_12_best_graph_gen_1276.graphml'\n",
    "\n",
    "# Read the graph\n",
    "graph = nx.read_graphml(graph_file_to_check)\n",
    "\n",
    "# Retrieve the attributes\n",
    "instance_class = graph.graph.get('instance_class', 'Attribute not found')\n",
    "weight_type = graph.graph.get('weight_type', 'Attribute not found')\n",
    "\n",
    "# Print the attributes\n",
    "print(f\"Graph: {graph_file_to_check}\")\n",
    "print(f\"Instance Class: {instance_class}\")\n",
    "print(f\"Weight Type: {weight_type}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
